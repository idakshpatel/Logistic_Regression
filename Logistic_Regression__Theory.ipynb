{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mDwa_KFXOZW"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "Logistic Regression is a classification algorithm used to predict the probability of a categorical outcome. It differs from Linear Regression as follows:\n",
        "\n",
        "Linear Regression is used for continuous outputs, while Logistic Regression is used for binary/multiclass classification.\n",
        "Logistic Regression applies a sigmoid function to map predicted values between 0 and 1, while Linear Regression predicts any real-valued output.\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "The sigmoid function maps any real number to a probability range between 0 and 1, making it suitable for classification problems.\n",
        "\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "Regularization prevents overfitting by adding a penalty term to the cost function. The two common types are:\n",
        "\n",
        "L1 (Lasso) Regularization: Adds absolute values of coefficients, leading to feature selection.\n",
        "L2 (Ridge) Regularization: Adds squared values of coefficients, reducing large weights but keeping all features.\n",
        "\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "Lasso (L1): Shrinks some coefficients to zero, effectively selecting important features.\n",
        "Ridge (L2): Shrinks coefficients but does not set any to zero.\n",
        "Elastic Net: Combines both L1 and L2, useful when features are correlated.\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "Use Elastic Net when there are many correlated features because Lasso may randomly pick one, while Ridge keeps all.\n",
        "\n",
        "\n",
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        "Higherλ → Increases regularization, reducing overfitting but may underfit.\n",
        "Lower λ → Reduces regularization, improving training accuracy but may overfit.\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "Linear relationship between independent variables and log-odds.\n",
        "No multicollinearity (independent variables should not be highly correlated).\n",
        "Large sample size for stable estimates.\n",
        "No extreme outliers affecting predictions.\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "Decision Trees\n",
        "Random Forest\n",
        "Support Vector Machines (SVM)\n",
        "Naïve Bayes\n",
        "Neural Networks\n",
        "\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "Leads to biased predictions toward the majority class.\n",
        "Solutions:\n",
        "Oversampling the minority class.\n",
        "Undersampling the majority class.\n",
        "Using Weighted Loss Function or SMOTE (Synthetic Minority Over-sampling Technique).\n",
        "\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "Regularization parameter (λ): Controls model complexity.\n",
        "Solver selection: Different solvers optimize differently.\n",
        "Handling imbalanced data: Adjust class weights.\n",
        "Grid Search or Random Search is used for finding optimal hyperparameters.\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "\n",
        "lbfgs: Works well for small datasets.\n",
        "saga: Works with large datasets and L1 regularization.\n",
        "liblinear: Suitable for small datasets, supports L1 and L2.\n",
        "newton-cg: Works well with L2 regularization.\n",
        "\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "One-vs-Rest (OvR): Trains multiple binary classifiers.\n",
        "Softmax Regression: Generalizes Logistic Regression for multiple classes.\n",
        "\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Simple and interpretable.\n",
        "Fast and efficient on small datasets.\n",
        "Works well when features are linearly separable.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Struggles with non-linear relationships.\n",
        "Sensitive to outliers and correlated features.\n",
        "Assumes no multicollinearity.\n",
        "\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "\n",
        "Spam detection (Email classification).\n",
        "Credit scoring (Loan approval).\n",
        "Disease prediction (Diabetes detection).\n",
        "Customer churn prediction.\n",
        "\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "Logistic Regression: Used for binary classification.\n",
        "Softmax Regression: Used for multiclass classification, assigns probabilities across multiple classes.\n",
        "\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "Use OvR when:\n",
        "Number of classes is small.\n",
        "Faster training is needed.\n",
        "Use Softmax when:\n",
        "There are many classes.\n",
        "Probability distributions across all classes are required.\n",
        "\n",
        "\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "\n",
        "Each coefficient represents the log-odds change of the dependent variable per unit change in\n",
        "Exp(ß) gives the odds ratio for feature importance.\n",
        "Positive {3 —i Increases probability of class 1.\n",
        "Negative -4 Decreases probability of class 1.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}